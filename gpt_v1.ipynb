{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f326447b-28a7-4c70-a1af-490f85a61c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "block_size = 128\n",
    "batch_size = 32\n",
    "n_embd = 256\n",
    "n_layer = 4\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "\n",
    "\n",
    "max_iters = 1000\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 250\n",
    "\n",
    "# device side assert trigger errors\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# batch_size = args.batch_size # to use the batch_size cmd arg -> python file_name.py -batch_size 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "338579f0-c6a4-4061-9bf1-018ebec05f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('wizard-of-oz.txt', 'r', encoding='utf-8') as f:\n",
    "#     text = f.read()\n",
    "\n",
    "# chars = sorted(set(text))\n",
    "# print(chars)\n",
    "\n",
    "# vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41115646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '1', '10', '106', '11', '12', '120', '13', '131', '14', '142', '15', '16', '160', '17', '172', '18', '187', '19', '1908', '2', '20', '203', '217', '23', '231', '240', '251', '3', '4', '41', '5', '55', '6', '64', '7', '77', '8', '88', '9', '95', ':', ';', '?', 'A', 'AGAIN', 'AIR', 'ALL', 'AND', 'ANOTHER', 'ARE', 'ARRIVAL', 'AUTHOR', 'About', 'Accuser', 'Adjustable', 'After', 'Afterward', 'Ah', 'Ahem', 'All', 'Alluring', 'Almost', 'Also', 'Am', 'Ambroise', 'America', 'American', 'An', 'And', 'Angeles', 'Animals', 'Another', 'Anu', 'Any', 'Anyhow', 'Anyone', 'Arabian', 'Are', 'Armies', 'Army', 'Around', 'As', 'Assorted', 'At', 'Athletic', 'Athletics', 'Atlantis', 'Aunt', 'Australia', 'Away', 'Awful', 'B', 'BAUM', 'BEARS', 'BEING', 'BELT', 'BLACK', 'BOOKS', 'BOY', 'BRAIDED', 'BUGGY', 'BY', 'Bah', 'Bailum', 'Band', 'Banner', 'Barney', 'Baum', 'Be', 'Bears', 'Beasts', 'Because', 'Before', 'Behind', 'Behold', 'Being', 'Below', 'Belt', 'Besides', 'Bill', 'Billina', 'Black', 'Blackness', 'Book', 'Breakfast', 'Bug', 'Buggy', 'Bush', 'But', 'By', 'CAB', 'CHAPTER', 'CHAPTERS', 'CITY', 'CLOUD', 'CO', 'COME', 'COPYRIGHT', 'CORONADO', 'COURT', 'CUT', 'Cab', 'California', 'Californy', 'Calling', 'Can', 'Canary', 'Captain', 'Captains', 'Carry', 'Cats', 'Cause', 'Certainly', 'Champion', 'Chapter', 'Cheer', 'Cheese', 'Chicago', 'Chief', 'Chopper', 'Citizens', 'City', 'Clinging', 'Cloud', 'College', 'Come', 'Consolidated', 'Cornet', 'Could', 'Couldn', 'Country', 'Court', 'Cowardly', 'Crack', 'Crash', 'Creatures', 'D', 'DANGER', 'DANGEROUS', 'DEDICATED', 'DEN', 'DOROTHY', 'DRAGON', 'DRAGONETTES', 'Dean', 'Dear', 'Demands', 'Destroyer', 'Did', 'Didn', 'Diggs', 'Directly', 'Do', 'Does', 'Don', 'Dorothy', 'Dragon', 'Dreadful', 'During', 'E', 'EARTHQUAKE', 'ESCAPE', 'ESCAPING', 'ETC', 'EUREKA', 'EXACTLY', 'EXCLAIMED', 'Each', 'Earth', 'Eat', 'Educated', 'Eh', 'Em', 'Emerald', 'Emmannuel', 'End', 'Eureka', 'Europe', 'Ev', 'Even', 'Everybody', 'Everything', 'Exactly', 'FAIRIES', 'FELL', 'FIGHT', 'FIRED', 'FLOUNDERED', 'FLUTTERED', 'FOR', 'FRANK', 'FRIENDS', 'FROM', 'Fairies', 'Far', 'Fellow', 'Fetch', 'Finally', 'First', 'Fish', 'Fishes', 'Flop', 'Flutters', 'Fly', 'Flying', 'Folks', 'Follow', 'Following', 'For', 'Forest', 'Francisco', 'Frisco', 'From', 'Fruits', 'GARDEN', 'GARGOYLES', 'GLASS', 'GOODNESS', 'Gabazoos', 'Gale', 'Garden', 'Gargoyle', 'Gargoyles', 'General', 'Generals', 'Getting', 'Gid', 'Gillikins', 'Give', 'Glinda', 'Go', 'Good', 'Goodness', 'Gradually', 'Great', 'Green', 'Greeting', 'Guess', 'Gump', 'Gurgles', 'Gwig', 'H', 'HAIR', 'HARRIET', 'HER', 'HORSE', 'HUNGRY', 'Ha', 'Had', 'Half', 'Have', 'Haven', 'Having', 'He', 'Head', 'Hearing', 'Hello', 'Hen', 'Henkle', 'Henry', 'Her', 'Here', 'Highly', 'Highness', 'His', 'Holes', 'Horse', 'Horses', 'House', 'How', 'However', 'Hugson', 'Hungry', 'Hush', 'I', 'ILLUSTRATED', 'IN', 'INC', 'INTO', 'INVISIBLE', 'IT', 'Ianu', 'If', 'Illustration', 'Immediately', 'Imperial', 'Imported', 'In', 'Indeed', 'Inside', 'Instantly', 'Instead', 'Is', 'Isaac', 'Island', 'Isn', 'It', 'Its', 'JIM', 'JOHN', 'Jamb', 'Jellia', 'Jim', 'Jinjur', 'Jump', 'Jumping', 'Jury', 'Just', 'Justice', 'KEEP', 'KINDNESS', 'KINGDOM', 'KITTEN', 'Kansas', 'Kentucky', 'King', 'Kingdom', 'Kitten', 'Kittens', 'L', 'LAND', 'LEAF', 'LESSON', 'LIKE', 'LIST', 'Lady', 'Land', 'Let', 'Life', 'Lion', 'Look', 'Looking', 'Lord', 'Los', 'M', 'MADE', 'MAGIC', 'MAN', 'MANGABOOS', 'MEET', 'MORROW', 'MOUNTAIN', 'MT', 'MUCH', 'Machine', 'Magic', 'Magnified', 'Make', 'Man', 'Mangaboo', 'Mangaboos', 'Many', 'May', 'Mombi', 'More', 'Mortals', 'Mother', 'Mountain', 'Mr', 'Munchkin', 'Munchkins', 'My', 'N', 'NEAL', 'NEILL', 'NEW', 'NINE', 'NOW', 'National', 'Naught', 'Neither', 'Never', 'Nevertheless', 'Next', 'Nick', 'Nights', 'Nine', 'No', 'Nobody', 'Nome', 'None', 'Nonsense', 'Norman', 'North', 'Not', 'Nothing', 'Noticing', 'Now', 'O', 'OBLIGED', 'OF', 'OLD', 'ON', 'OUT', 'OZ', 'OZMA', 'Oatmeal', 'Oats', 'Of', 'Official', 'Oh', 'Old', 'Omaha', 'On', 'Once', 'One', 'Only', 'Opening', 'Oscar', 'Other', 'Others', 'Otherwise', 'Our', 'Over', 'Overman', 'Oz', 'Ozite', 'Ozites', 'Ozma', 'P', 'PAGE', 'PARASOL', 'PEOPLE', 'PERFORMS', 'PICKS', 'PIGLET', 'PIGLETS', 'PIT', 'POKED', 'PORTRAIT', 'PRINCESS', 'PROVE', 'PYRAMID', 'Pah', 'People', 'Perceiving', 'Perhaps', 'Permit', 'Phadrig', 'Phoo', 'Piglets', 'Pit', 'Please', 'Post', 'Powder', 'Presently', 'President', 'Pretty', 'Prickly', 'Prince', 'Princes', 'Princess', 'Prisoner', 'Probably', 'Professor', 'Prove', 'Public', 'Pull', 'Pyramid', 'Quadlings', 'Quick', 'Quite', 'R', 'RANCH', 'REALLY', 'RESERVED', 'RETURNS', 'REUNITED', 'RIGHT', 'RIGHTS', 'ROOM', 'Rain', 'Rains', 'Ranch', 'Readers', 'Real', 'Really', 'Respected', 'Room', 'Royal', 'Royalty', 'Ruler', 'Rulers', 'Run', 'Rustles', 'S', 'SAKE', 'SIGNAL', 'SLOWLY', 'SORCERER', 'SORT', 'STOOD', 'Said', 'San', 'Saw', 'Sawhorse', 'Scarecrow', 'Science', 'Scientific', 'See', 'Seems', 'Sending', 'Several', 'She', 'Shoes', 'Shows', 'Siding', 'Silver', 'Sir', 'Slowly', 'So', 'Some', 'Sometimes', 'Soon', 'Sorcerer', 'Sorcerers', 'Sorry', 'South', 'Spangled', 'Star', 'States', 'Step', 'Steward', 'Still', 'Stones', 'Stop', 'Such', 'Suddenly', 'Suppose', 'Surely', 'Swiftly', 'Swiss', 'T', 'TEACHES', 'THE', 'THERE', 'THEY', 'THIS', 'THRONG', 'THROUGH', 'TIGER', 'TINY', 'TO', 'TOOK', 'TREMBLING', 'TRIAL', 'TRICK', 'TWO', 'Take', 'Taken', 'Talk', 'Tastes', 'Teenty', 'Tell', 'Terrible', 'Thank', 'That', 'The', 'Their', 'Then', 'There', 'These', 'They', 'This', 'Thoroughly', 'Those', 'Thought', 'Throne', 'Throwing', 'Tiger', 'Tik', 'Tin', 'Tiny', 'Tip', 'To', 'Today', 'Tomorrow', 'Toto', 'Train', 'True', 'Tut', 'Twining', 'Two', 'USES', 'Uncle', 'Under', 'Unfortunately', 'Unhitch', 'United', 'Unless', 'VALLEY', 'VEGETABLE', 'VOICES', 'Valley', 'Vegetable', 'Very', 'Vines', 'Voe', 'WARNING', 'WHAT', 'WHY', 'WILLIAM', 'WITH', 'WIZARD', 'WONDER', 'WONDERFUL', 'WOODEN', 'Wait', 'Was', 'Watch', 'Watching', 'We', 'Weent', 'Well', 'Were', 'What', 'When', 'Whenever', 'Where', 'Wherever', 'Which', 'Who', 'Whoa', 'Why', 'Wicked', 'Will', 'Winkies', 'Wish', 'Witch', 'Witches', 'With', 'Wizard', 'Woggle', 'Wonderful', 'Wooden', 'Woodman', 'Woogh', 'Working', 'Would', 'YORK', 'YOU', 'YOUR', 'Yellow', 'Yes', 'Yet', 'You', 'Young', 'Your', 'Z', 'ZEB', 'Zeb', 'Zebediah', 'Zoroaster', '[', ']', '_I_', '_We_', '_almost_', '_any_', '_beau', '_can_', '_climb_', '_down_', '_go_', '_immejitly_', '_is_', '_know_', '_me_', '_one_', '_real_', '_we_', '_went_', '_you_', 'a', 'abandon', 'able', 'about', 'above', 'abroad', 'abruptly', 'absence', 'absurd', 'absurdly', 'abundance', 'accent', 'accept', 'accepted', 'accepting', 'accident', 'accidents', 'accompanied', 'accompany', 'accomplishes', 'account', 'accuse', 'accused', 'accuses', 'accusing', 'ache', 'achievement', 'acknowledge', 'acknowledged', 'acquaintance', 'acquainted', 'acquire', 'across', 'act', 'acted', 'action', 'actions', 'active', 'activity', 'actually', 'add', 'added', 'addressed', 'addressing', 'admirable', 'admiration', 'admire', 'admiringly', 'admitted', 'admonished', 'adopt', 'adorable', 'advance', 'advanced', 'advantage', 'adventure', 'adventurers', 'adventures', 'advise', 'advised', 'advisors', 'affair', 'afraid', 'after', 'afternoon', 'afterward', 'again', 'against', 'age', 'aggregation', 'ago', 'agree', 'agreed', 'ahead', 'aid', 'air', 'ajar', 'alarm', 'alighted', 'alike', 'alive', 'all', 'alligators', 'allow', 'allowed', 'almost', 'aloft', 'alone', 'along', 'already', 'also', 'although', 'altogether', 'always', 'am', 'amazed', 'amazement', 'amazing', 'ambition', 'ambled', 'amid', 'among', 'amongst', 'amount', 'amounted', 'ample', 'amply', 'amuse', 'amused', 'amusement', 'amusements', 'amusing', 'an', 'and', 'anger', 'angrily', 'angry', 'animal', 'animals', 'animated', 'announced', 'another', 'answer', 'answered', 'antics', 'antlered', 'anxious', 'anxiously', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'apart', 'apartment', 'apartments', 'apology', 'apparent', 'appeal', 'appealing', 'appear', 'appearance', 'appeared', 'appears', 'appetite', 'appetizing', 'applauded', 'applause', 'applying', 'appointed', 'appreciate', 'approval', 'apt', 'aptly', 'arch', 'arched', 'arching', 'archway', 'are', 'arguments', 'aristocratic', 'arm', 'arms', 'army', 'arose', 'around', 'aroused', 'arranged', 'arrest', 'arrival', 'arrivals', 'arrive', 'arrived', 'arrogant', 'art', 'article', 'articles', 'arts', 'as', 'ascend', 'ascended', 'ascending', 'ascensions', 'ashamed', 'ask', 'asked', 'asleep', 'assemblage', 'assembled', 'assert', 'asserted', 'assist', 'assistance', 'assisted', 'associate', 'associating', 'assorted', 'assortment', 'assurance', 'assure', 'assured', 'astonished', 'astonishing', 'astonishment', 'at', 'ate', 'atmosphere', 'attached', 'attack', 'attacked', 'attain', 'attempt', 'attend', 'attendant', 'attendants', 'attended', 'attention', 'attracted', 'attraction', 'attractive', 'attractively', 'attracts', 'audience', 'aunt', 'authority', 'average', 'avoid', 'awake', 'awakened', 'aware', 'away', 'awed', 'awful', 'awfully', 'awhile', 'awkward', 'awoke', 'axe', 'b', 'babies', 'baby', 'babyish', 'back', 'backed', 'backs', 'bad', 'bade', 'badly', 'baggage', 'bait', 'bake', 'baked', 'balance', 'balanced', 'bald', 'ball', 'balloon', 'balls', 'band', 'bang', 'bangs', 'bank', 'banks', 'bare', 'bared', 'barrels', 'barrier', 'bars', 'bashfully', 'basket', 'baskets', 'bath', 'bathed', 'battered', 'battle', 'be', 'beaks', 'bear', 'beard', 'bearers', 'bearing', 'bears', 'beast', 'beastly', 'beasts', 'beat', 'beating', 'beats', 'beauties', 'beautiful', 'beautifully', 'beauty', 'became', 'because', 'become', 'becomes', 'becoming', 'bed', 'beds', 'been', 'bees', 'before', 'beg', 'began', 'begged', 'begging', 'begin', 'beginning', 'begun', 'behave', 'behaved', 'beheld', 'behind', 'behold', 'being', 'beings', 'believe', 'believed', 'believes', 'bell', 'bells', 'belong', 'belonged', 'beloved', 'below', 'bench', 'benches', 'beneath', 'bent', 'berry', 'beside', 'best', 'bet', 'better', 'between', 'bewildered', 'beyond', 'big', 'bigger', 'biggest', 'bigness', 'billows', 'bird', 'birdcage', 'birds', 'birth', 'bit', 'bite', 'biting', 'bits', 'bitten', 'bitterly', 'black', 'blade', 'blades', 'blame', 'ble', 'bleed', 'blind', 'blinded', 'blinked', 'blinking', 'blocked', 'blood', 'blooming', 'blossom', 'blow', 'blown', 'blue', 'blues', 'bly', 'board', 'boards', 'boats', 'bodice', 'bodies', 'bodily', 'body', 'boldly', 'bones', 'boney', 'bonfire', 'bony', 'book', 'books', 'boost', 'bore', 'bored', 'born', 'borrow', 'bosom', 'bossed', 'both', 'bother', 'bothered', 'bottom', 'boudoir', 'bound', 'bout', 'bow', 'bowed', 'bowing', 'bowl', 'bows', 'bowsprits', 'box', 'boxes', 'boxing', 'boy', 'boys', 'brace', 'bracelets', 'braid', 'braided', 'braids', 'brains', 'branch', 'branches', 'brave', 'bravery', 'bread', 'break', 'breakfast', 'breakfasted', 'breaking', 'breast', 'breath', 'breathe', 'breathed', 'breathless', 'breaths', 'breeding', 'bridges', 'bright', 'brightly', 'brilliant', 'brilliantly', 'brim', 'bring', 'briskly', 'broad', 'broaden', 'broader', 'broadest', 'brocades', 'broke', 'broken', 'brook', 'brooks', 'brother', 'brothers', 'brought', 'brow', 'brown', 'browsing', 'brushing', 'bubbling', 'buckle', 'buckled', 'buckles', 'bud', 'buffaloes', 'bug', 'buggy', 'building', 'buildings', 'built', 'bullet', 'bullets', 'bunch', 'bunting', 'burnished', 'bury', 'bush', 'bushes', 'bushy', 'busily', 'business', 'busy', 'but', 'buttoned', 'buttons', 'buy', 'by', 'bye', 'cab', 'cabbages', 'cackling', 'cage', 'call', 'called', 'calling', 'calm', 'calmly', 'came', 'can', 'cancel', 'cannon', 'cannot', 'canopy', 'captor', 'captors', 'captured', 'car', 'card', 'care', 'cared', 'careful', 'carefully', 'careless', 'carelessly', 'carried', 'carry', 'carrying', 'cars', 'carved', 'case', 'cast', 'cat', 'catch', 'catching', 'cats', 'catsup', 'caught', 'cause', 'caused', 'caution', 'cautioned', 'cautiously', 'cave', 'cavern', 'caves', 'cease', 'ceased', 'ceases', 'cellar', 'center', 'central', 'centuries', 'ceremonies', 'ceremony', 'certain', 'certainly', 'chair', 'chairs', 'challenge', 'chamber', 'chambers', 'champion', 'chance', 'chances', 'change', 'changed', 'changing', 'charge', 'charging', 'chariot', 'charm', 'charming', 'chase', 'chasm', 'chatter', 'cheek', 'cheered', 'cheerful', 'cheerfully', 'cheers', 'cheery', 'cherries', 'chest', 'chew', 'chief', 'child', 'childish', 'children', 'chinks', 'chins', 'chipped', 'choose', 'chooses', 'chopped', 'chose', 'chuckled', 'chuckles', 'chunk', 'chunks', 'cir', 'circle', 'circled', 'circular', 'circumstances', 'circus', 'cities', 'citizens', 'city', 'claim', 'clap', 'clapped', 'clatter', 'claw', 'claws', 'clay', 'cleaned', 'clear', 'clearer', 'clearly', 'clever', 'cleverly', 'climb', 'climbed', 'climbing', 'clock', 'clockwork', 'close', 'closed', 'closely', 'closets', 'cloth', 'clothed', 'clothes', 'clothing', 'cloud', 'clouds', 'clover', 'club', 'clumsy', 'clung', 'clustered', 'clusters', 'clutched', 'coal', 'coals', 'coarse', 'coat', 'cold', 'coldly', 'collar', 'collecting', 'college', 'color', 'colored', 'colors', 'colt', 'combat', 'combed', 'come', 'comes', 'comfort', 'comfortable', 'comfortably', 'comforted', 'comforting', 'comical', 'coming', 'command', 'commanded', 'commands', 'commenced', 'commit', 'committed', 'common', 'commonplace', 'companion', 'companions', 'companionship', 'company', 'compared', 'complain', 'complained', 'completed', 'completely', 'complexions', 'composed', 'composedly', 'comrades', 'concealed', 'concerned', 'condemned', 'condition', 'conditions', 'conduct', 'conductor', 'cone', 'confess', 'confession', 'confidence', 'confident', 'confined', 'confinement', 'confining', 'confused', 'confusion', 'connection', 'conquer', 'conquered', 'conscience', 'consciences', 'consciousness', 'consented', 'consider', 'considerable', 'consideration', 'considered', 'consist', 'consisted', 'constant', 'constantly', 'constructed', 'consumed', 'contain', 'containing', 'contains', 'contemptuous', 'content', 'contented', 'contentedly', 'continually', 'continue', 'continued', 'control', 'controlled', 'convenience', 'conversation', 'converse', 'conversed', 'convincing', 'cook', 'cool', 'copper', 'cord', 'cordially', 'cords', 'cork', 'corner', 'cornered', 'corners', 'coronet', 'correcting', 'correspondents', 'costume', 'costumes', 'cottage', 'cottages', 'cotton', 'could', 'couldn', 'counsel', 'count', 'countenance', 'countries', 'country', 'courage', 'courageous', 'course', 'court', 'courtiers', 'courtyard', 'cousins', 'covered', 'coward', 'cows', 'crack', 'cracked', 'crackers', 'crackle', 'cracks', 'crash', 'crawl', 'crawled', 'crazy', 'creaked', 'create', 'created', 'creating', 'creature', 'creatures', 'credit', 'creeping', 'crept', 'crestfallen', 'cried', 'crime', 'criminal', 'criss', 'criticise', 'crocodiles', 'crooked', 'cross', 'crouched', 'crowd', 'crowded', 'crowds', 'crown', 'crowned', 'cruel', 'crunching', 'crush', 'crushed', 'crushing', 'crust', 'cry', 'crystal', 'cuddled', 'cuff', 'cunning', 'cup', 'curiosity', 'curious', 'curiously', 'curled', 'current', 'curtains', 'curve', 'curved', 'curving', 'cut', 'cuts', 'cutting', 'cyclone', 'd', 'daintily', 'dainty', 'dama', 'damage', 'damaging', 'damas', 'damp', 'dampness', 'danced', 'danger', 'dangerous', 'dangerously', 'dangle', 'dap', 'dare', 'dared', 'daring', 'dark', 'darkened', 'darker', 'darkness', 'dart', 'darting', 'dash', 'dashboard', 'dashed', 'dashing', 'daunted', 'dawn', 'day', 'daylight', 'days', 'dazed', 'dazzled', 'dead', 'deadly', 'deal', 'dear', 'dearly', 'dears', 'death', 'deceive', 'decent', 'deception', 'decide', 'decided', 'decidedly', 'decides', 'declare', 'declared', 'decorated', 'decorating', 'decree', 'deep', 'defeat', 'defeated', 'defend', 'defenders', 'defference', 'defiantly', 'delayed', 'delicate', 'delicately', 'delicious', 'delight', 'delighted', 'delightedly', 'delightful', 'demand', 'demanded', 'demanding', 'demurely', 'den', 'deny', 'departed', 'depended', 'depends', 'depose', 'depraved', 'depths', 'descend', 'descended', 'descending', 'describe', 'deserted', 'deserts', 'deserve', 'deserves', 'designs', 'desire', 'desired', 'desires', 'desperate', 'despondent', 'despondently', 'destined', 'destroy', 'destroyed', 'detail', 'devoid', 'devote', 'devoted', 'devour', 'devoured', 'diamond', 'diamonds', 'did', 'didn', 'die', 'died', 'differ', 'differed', 'different', 'difficult', 'difficulties', 'difficulty', 'dig', 'dignified', 'dignity', 'dim', 'dimly', 'dine', 'dinner', 'dint', 'direction', 'directions', 'directly', 'dirty', 'disabled', 'disagreeable', 'disappear', 'disappeared', 'disappointment', 'disarranged', 'disclosing', 'discontented', 'discouraged', 'discover', 'discovered', 'disdain', 'disgrace', 'disguise', 'dish', 'dishes', 'disliked', 'dismal', 'dismally', 'dismay', 'dismissed', 'display', 'displayed', 'displaying', 'dispose', 'dispute', 'distance', 'distant', 'distinct', 'distinguish', 'distinguished', 'distress', 'distressed', 'disturbed', 'divide', 'divided', 'do', 'does', 'doesn', 'dog', 'doing', 'dollars', 'dolls', 'domain', 'dome', 'domed', 'domes', 'don', 'done', 'donkey', 'doom', 'door', 'doors', 'doorway', 'doorways', 'dotting', 'double', 'doubt', 'doubtfully', 'doubtless', 'doubts', 'doughnuts', 'down', 'downward', 'doze', 'dozen', 'dozens', 'drag', 'dragged', 'dragon', 'dragonette', 'dragonettes', 'dragons', 'draw', 'drawing', 'drawled', 'drawn', 'draws', 'dre', 'dread', 'dreadful', 'dreadfully', 'dreamed', 'dress', 'dressed', 'dressing', 'drew', 'dripping', 'drive', 'driven', 'driveway', 'driving', 'drooping', 'drop', 'dropped', 'drops', 'drove', 'drowned', 'ducked', 'dug', 'dull', 'dummies', 'dummy', 'during', 'duty', 'dwelling', 'dwellings', 'dwindled', 'dying', 'each', 'eager', 'eagerly', 'eagerness', 'ear', 'early', 'earnestly', 'ears', 'earth', 'earthquake', 'earthquakes', 'ease', 'easier', 'easiest', 'easily', 'east', 'easy', 'eat', 'eaten', 'eating', 'eats', 'echoed', 'edge', 'edgewise', 'educated', 'effect', 'eight', 'either', 'elaborate', 'elephant', 'elephants', 'elevated', 'eleven', 'else', 'em', 'embarrassment', 'emerald', 'emeralds', 'emerged', 'empty', 'enable', 'enabled', 'enables', 'enchanted', 'enchantments', 'enclosed', 'enclosure', 'encounter', 'encountered', 'encrusted', 'end', 'ended', 'ends', 'endure', 'enduring', 'enemies', 'enemy', 'energy', 'engaged', 'engagements', 'engineer', 'engulfed', 'enjoy', 'enjoyed', 'enormous', 'enough', 'enquire', 'enquired', 'enraptured', 'enter', 'entered', 'enticing', 'entire', 'entirely', 'entombed', 'entrance', 'envy', 'equal', 'equally', 'erect', 'errand', 'escape', 'escaped', 'escaping', 'escort', 'escorted', 'especially', 'esteemed', 'evasively', 'even', 'evening', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'evidence', 'evident', 'evidently', 'evil', 'exact', 'exactly', 'exalted', 'examine', 'examined', 'examining', 'example', 'exceedingly', 'excellent', 'except', 'exchanged', 'exchanging', 'excited', 'excitement', 'exclaimed', 'excursion', 'excuse', 'executed', 'exercise', 'exhibit', 'exist', 'expectantly', 'expected', 'expecting', 'experience', 'experienced', 'experiences', 'explain', 'explained', 'explaining', 'explains', 'explore', 'explored', 'exposed', 'express', 'expressed', 'expression', 'expressionless', 'exquisite', 'exquisitely', 'extended', 'extends', 'extraordinarily', 'extraordinary', 'extreme', 'extremely', 'eye', 'eyed', 'eyeing', 'eyelids', 'eyes', 'face', 'faced', 'faces', 'facing', 'fact', 'factory', 'facts', 'fail', 'failed', 'faint', 'fair', 'fairies', 'fairly', 'fairy', 'fairyland', 'faithful', 'fall', 'fallen', 'falling', 'fame', 'family', 'famous', 'fancy', 'fantastic', 'far', 'farewell', 'farm', 'farther', 'fascinated', 'fast', 'fasten', 'fastened', 'faster', 'fat', 'fate', 'father', 'fault', 'favorite', 'fear', 'feared', 'fearfully', 'fearsome', 'feats', 'features', 'fed', 'feed', 'feel', 'feeling', 'feet', 'feline', 'fell', 'fellow', 'fellows', 'felt', 'ferocious', 'festivity', 'fetch', 'fetched', 'fetlocks', 'few', 'field', 'fields', 'fierce', 'fiercely', 'fiercer', 'fight', 'fighting', 'figure', 'fill', 'filled', 'final', 'finally', 'find', 'finding', 'fine', 'finely', 'finest', 'finger', 'fingers', 'finished', 'fire', 'fired', 'fireplace', 'firm', 'first', 'fish', 'fishes', 'fit', 'fitted', 'five', 'fix', 'fixture', 'flabby', 'flag', 'flags', 'flame', 'flames', 'flaming', 'flanks', 'flat', 'fleecy', 'fleet', 'flesh', 'flew', 'flicked', 'flicker', 'flies', 'flight', 'float', 'floated', 'floating', 'flock', 'flocked', 'flood', 'flooded', 'floor', 'flooring', 'flop', 'flopped', 'floundered', 'flowed', 'flower', 'flowers', 'flowing', 'fluffy', 'flung', 'flutter', 'fluttered', 'flutters', 'fly', 'flying', 'foam', 'foes', 'folds', 'folk', 'folks', 'follow', 'followed', 'fond', 'food', 'fool', 'foolish', 'foolishness', 'foot', 'for', 'forbid', 'forbidden', 'forbidding', 'force', 'forehead', 'forest', 'forever', 'forget', 'forgot', 'forgotten', 'forks', 'form', 'formed', 'former', 'forms', 'fortunately', 'fortune', 'forward', 'fought', 'found', 'fountains', 'four', 'fourth', 'fowl', 'fragments', 'fragrance', 'fragrant', 'fraid', 'frank', 'frankly', 'frantic', 'frantically', 'fray', 'freak', 'free', 'freed', 'freely', 'fresh', 'freshly', 'friend', 'friendliness', 'friendly', 'friends', 'friendship', 'fright', 'frighten', 'frightened', 'frisk', 'frisking', 'frolicking', 'from', 'front', 'frown', 'fruit', 'fruits', 'ful_', 'fulfill', 'full', 'fully', 'fun', 'funnel', 'funny', 'fur', 'furiously', 'furnished', 'further', 'furthest', 'fuss', 'fussy', 'future', 'gaily', 'gait', 'gallery', 'galloping', 'gambolling', 'games', 'garden', 'gardens', 'gas', 'gashes', 'gasp', 'gasped', 'gasps', 'gates', 'gather', 'gave', 'gaze', 'gazed', 'gazing', 'generally', 'gentle', 'gentleness', 'gently', 'get', 'gets', 'getting', 'girl', 'girlish', 'girls', 'give', 'gives', 'glad', 'gladdened', 'glance', 'glances', 'glare', 'glaring', 'glass', 'gleamed', 'gleaming', 'gleefully', 'glistened', 'glistening', 'glitter', 'glittered', 'gloom', 'gloomily', 'gloomy', 'glowing', 'go', 'gobbled', 'goes', 'going', 'gold', 'golden', 'gone', 'good', 'goodness', 'goods', 'gorgeous', 'gorgeously', 'got', 'gown', 'gowns', 'grabbed', 'grace', 'graceful', 'gracefully', 'gracious', 'graciously', 'grade', 'grand', 'grandfather', 'granite', 'grasped', 'grasping', 'grass', 'grasshoppers', 'grateful', 'gratefully', 'gratified', 'gratitude', 'grave', 'gravely', 'gravey', 'gravitation', 'gray', 'grazed', 'grazing', 'great', 'greater', 'greatest', 'greatly', 'greedily', 'greedy', 'green', 'greenish', 'greet', 'greeted', 'grew', 'greys', 'grieve', 'grieved', 'grinding', 'grinning', 'grip', 'groan', 'groaned', 'ground', 'grounds', 'group', 'groups', 'groves', 'grow', 'growing', 'growl', 'growled', 'growling', 'growls', 'grown', 'grows', 'growth', 'gruff', 'gruffly', 'grumbled', 'grunt', 'grunted', 'grunting', 'grunts', 'guess', 'guessing', 'guest', 'guests', 'guidance', 'guide', 'guilty', 'ha', 'habit', 'had', 'hadn', 'hair', 'hairs', 'half', 'hall', 'halls', 'halted', 'halves', 'hand', 'handed', 'handkerchief', 'handkerchiefs', 'handle', 'handling', 'hands', 'handsome', 'hanging', 'happen', 'happened', 'happenings', 'happens', 'happy', 'hard', 'hardest', 'hardly', 'hardness', 'harm', 'harness', 'harnessed', 'harsh', 'has', 'hasn', 'haste', 'hasten', 'hastened', 'hastily', 'hasty', 'hat', 'hats', 'haughty', 'haunches', 'have', 'haven', 'having', 'he', 'head', 'headed', 'headlong', 'heads', 'heap', 'heaped', 'heaps', 'hear', 'heard', 'hearing', 'heart', 'hearted', 'heartily', 'heartless', 'hearts', 'heat', 'heavy', 'hedge', 'heed', 'heels', 'height', 'held', 'help', 'helped', 'helpless', 'hen', 'her', 'here', 'hereafter', 'heroine', 'herself', 'hesitated', 'hesitating', 'hesitation', 'hid', 'hide', 'high', 'higher', 'hill', 'hills', 'hillside', 'him', 'himself', 'hind', 'hinges', 'his', 'history', 'hitched', 'hoarse', 'hold', 'holding', 'hole', 'holes', 'holiday', 'hollow', 'home', 'homelike', 'homes', 'honest', 'honestly', 'honor', 'hoof', 'hoofs', 'hook', 'hop', 'hope', 'hoped', 'hopeful', 'hoping', 'hopped', 'horrible', 'horrid', 'horrified', 'horror', 'horse', 'horses', 'hosts', 'hot', 'hour', 'hours', 'house', 'household', 'houses', 'hove', 'how', 'however', 'huddled', 'hues', 'hug', 'huge', 'hugged', 'human', 'humans', 'humbly', 'humbug', 'humbugs', 'hundred', 'hundreds', 'hunger', 'hungry', 'hunt', 'hunted', 'hunting', 'hurried', 'hurry', 'hurt', 'hush', 'idea', 'if', 'ignorant', 'ill', 'illuminated', 'imagine', 'imagined', 'imitation', 'imitations', 'immediately', 'immemorial', 'immense', 'impolite', 'importance', 'important', 'imposing', 'impossible', 'impressed', 'impression', 'impressive', 'imps', 'impudent', 'impulsively', 'in', 'incensed', 'incline', 'inclined', 'included', 'indeed', 'indicate', 'indignant', 'indignantly', 'individual', 'induced', 'indulged', 'inflicted', 'influence', 'influenced', 'informed', 'inhabit', 'inhabitant', 'inhabitants', 'inhabited', 'initials', 'injure', 'injured', 'injury', 'inner', 'innocence', 'innocent', 'insect', 'inside', 'insisted', 'inspecting', 'instant', 'instantly', 'instead', 'insults', 'intelligence', 'intelligent', 'intend', 'intended', 'intends', 'intently', 'interest', 'interested', 'interesting', 'interference', 'interrupt', 'interrupted', 'interview', 'into', 'introduce', 'introduced', 'intrude', 'intruder', 'intruders', 'invaluable', 'invented', 'inventor', 'invis', 'invisible', 'invitation', 'invited', 'inviting', 'iron', 'is', 'island', 'isn', 'it', 'its', 'ivory', 'jagged', 'jail', 'jailor', 'jamming', 'jar', 'jarred', 'jaws', 'jealous', 'jerked', 'jerky', 'jewel', 'jewelled', 'jewels', 'jiffy', 'jig', 'job', 'join', 'joined', 'jointed', 'joints', 'jolly', 'journey', 'journeying', 'joy', 'joyfully', 'joyous', 'joyously', 'judge', 'judgment', 'jugglers', 'jump', 'jumped', 'jumping', 'jungle', 'jury', 'just', 'justice', 'keen', 'keep', 'keeping', 'keeps', 'kept', 'kerosene', 'kick', 'kicked', 'kicking', 'kicks', 'kill', 'killed', 'kind', 'kindly', 'kindness', 'king', 'kingdom', 'kiss', 'kissed', 'kissing', 'kitten', 'kittens', 'kneeling', 'knees', 'knew', 'knives', 'knock', 'knocked', 'knocking', 'knot', 'knots', 'know', 'knowing', 'knowledge', 'known', 'knows', 'lace', 'lack', 'lacks', 'lad', 'ladies', 'lady', 'lagging', 'laid', 'lakes', 'lambs', 'land', 'landed', 'landing', 'landscape', 'language', 'lantern', 'lanterns', 'lap', 'large', 'largest', 'lashing', 'last', 'late', 'lately', 'later', 'latter', 'laugh', 'laughed', 'laughing', 'laughter', 'launched', 'lavender', 'law', 'lawn', 'lawns', 'lawyer', 'lay', 'lead', 'leading', 'leads', 'leaf', 'leagued', 'lean', 'leaned', 'leap', 'leaped', 'leaping', 'learned', 'least', 'leather', 'leathern', 'leave', 'leaved', 'leaves', 'leaving', 'led', 'left', 'leg', 'legs', 'length', 'less', 'lessons', 'lest', 'let', 'letter', 'letters', 'level', 'liable', 'liberate', 'liberty', 'licking', 'lids', 'lie', 'lies', 'lieve', 'life', 'lift', 'lifted', 'light', 'lighted', 'lighter', 'lighting', 'lightly', 'lights', 'like', 'liked', 'likely', 'likes', 'likewise', 'limb', 'limbs', 'line', 'lips', 'listen', 'listened', 'lithe', 'little', 'live', 'lived', 'lively', 'lives', 'living', 'll', 'loan', 'lock', 'lofty', 'log', 'lonely', 'long', 'longed', 'longer', 'longs', 'look', 'looked', 'looking', 'looks', 'loose', 'lose', 'loss', 'lost', 'lot', 'lots', 'loud', 'loudly', 'love', 'loved', 'loveliest', 'lovely', 'loves', 'loving', 'lovingly', 'low', 'lower', 'luck', 'lucky', 'luncheon', 'lungs', 'luscious', 'lustily', 'ly', 'lying', 'm', 'ma', 'machine', 'machinery', 'mad', 'made', 'madly', 'magic', 'magical', 'magnificence', 'magnificent', 'maid', 'maiden', 'mail', 'main', 'mainly', 'maintain', 'make', 'makes', 'making', 'mama', 'man', 'manage', 'managed', 'mane', 'manner', 'manners', 'manufacture', 'manufactured', 'manufacturer', 'manufacturing', 'many', 'mar', 'marble', 'marched', 'mark', 'maroon', 'married', 'marvelous', 'marvelously', 'mashed', 'mass', 'master', 'masters', 'match', 'matched', 'material', 'matted', 'matter', 'matters', 'may', 'me', 'meal', 'meals', 'mean', 'means', 'meant', 'meat', 'meddle', 'meekly', 'meet', 'melon', 'melons', 'members', 'men', 'menacing', 'menagerie', 'mend', 'mended', 'mercy', 'mere', 'merely', 'merrily', 'merry', 'messengers', 'met', 'metallic', 'mice', 'middle', 'midnight', 'might', 'mighty', 'mild', 'mile', 'miles', 'milk', 'mind', 'minded', 'mine', 'minute', 'minutes', 'mischief', 'miserable', 'miserably', 'misfortune', 'miss', 'missed', 'missing', 'mission', 'mistake', 'mistaken', 'mistakes', 'mistress', 'mixed', 'moan', 'mocking', 'modestly', 'moist', 'moldy', 'mollified', 'moment', 'moments', 'monarchs', 'money', 'month', 'moo', 'mood', 'moon', 'moons', 'more', 'morning', 'morsel', 'most', 'mother', 'motion', 'motionless', 'mount', 'mountain', 'mountains', 'mounted', 'mounting', 'mourning', 'mouse', 'mouth', 'mouthful', 'mouths', 'move', 'moved', 'moving', 'much', 'munch', 'murder', 'murderer', 'murdering', 'murderous', 'murmured', 'mus', 'muscle', 'music', 'must', 'muster', 'my', 'myself', 'mysteries', 'mysterious', 'mysteriously', 'mystery', 'mystic', 'n', 'name', 'named', 'names', 'nap', 'narrow', 'narrower', 'nasty', 'nations', 'native', 'natural', 'naturally', 'nature', 'naughty', 'near', 'nearby', 'neared', 'nearer', 'nearest', 'nearly', 'necessary', 'neck', 'need', 'needed', 'needn', 'needs', 'neigh', 'neighboring', 'neighbors', 'neighed', 'neither', 'nervous', 'nervously', 'nest', 'nestled', 'nestling', 'never', 'new', 'news', 'newspapers', 'next', 'nibble', 'nibbled', 'nice', 'nicely', 'nickle', 'niece', 'night', 'nine', 'no', 'noble', 'nobody', 'nodded', 'nodding', 'noise', 'noiseless', 'noiselessly', 'noises', 'none', 'noon', 'nor', 'nose', 'noses', 'not', 'note', 'nothing', 'notice', 'noticed', 'noting', 'novelty', 'now', 'number', 'numbers', 'numerous', 'o', 'oatmeal', 'oats', 'obey', 'obeyed', 'object', 'objected', 'obliged', 'obscured', 'observe', 'observed', 'occasion', 'occasional', 'occupants', 'occupied', 'occupy', 'occurred', 'occurs', 'odd', 'odds', 'odor', 'of', 'off', 'offender', 'offer', 'offered', 'office', 'officer', 'officers', 'officials', 'often', 'oh', 'oil', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'open', 'opened', 'opening', 'openings', 'opinion', 'oppose', 'opposing', 'opposite', 'or', 'orange', 'orchard', 'orchards', 'order', 'ordered', 'ordinary', 'ornament', 'ornamental', 'ornaments', 'other', 'others', 'otherwise', 'ought', 'our', 'ourselves', 'out', 'outer', 'outlet', 'outside', 'outward', 'oven', 'over', 'overcome', 'overgrown', 'overhead', 'overheard', 'overlook', 'overtake', 'overtaken', 'overtook', 'owe', 'owing', 'own', 'owned', 'owner', 'padded', 'pages', 'paid', 'pain', 'painted', 'pair', 'palace', 'pale', 'panic', 'panted', 'panting', 'parachute', 'parasol', 'pardon', 'parents', 'part', 'particular', 'parting', 'partition', 'partly', 'parts', 'party', 'pass', 'passage', 'passed', 'passengers', 'passes', 'past', 'patches', 'path', 'paths', 'patient', 'patiently', 'patted', 'patting', 'pause', 'pausing', 'pavement', 'paw', 'paws', 'pay', 'paying', 'pays', 'pea', 'peace', 'peach', 'peaked', 'peal', 'pearls', 'pebble', 'pebbles', 'peculiar', 'pedigree', 'peered', 'peering', 'pelting', 'penalty', 'people', 'perceive', 'perceived', 'perfect', 'perfection', 'perfectly', 'perform', 'performance', 'performed', 'performing', 'perfume', 'perfumed', 'perhaps', 'perilous', 'periods', 'permeated', 'permit', 'permitted', 'perplexed', 'perplexity', 'person', 'personage', 'personal', 'persons', 'pert', 'pet', 'pets', 'petting', 'pick', 'picked', 'picking', 'picture', 'picturesque', 'pie', 'piece', 'pieces', 'piercing', 'pig', 'piggy', 'piglet', 'piglets', 'pigs', 'pile', 'piled', 'piling', 'pin', 'pinhead', 'pink', 'pit', 'pityingly', 'pivot', 'place', 'placed', 'places', 'plain', 'plainly', 'plains', 'plaited', 'plan', 'plant', 'planted', 'planting', 'plants', 'plaster', 'plasters', 'plate', 'plated', 'plates', 'platform', 'platter', 'platters', 'play', 'played', 'playing', 'pleading', 'pleadingly', 'pleasant', 'pleasantly', 'please', 'pleased', 'pleases', 'pleasing', 'pleasure', 'pleasures', 'plentifully', 'plenty', 'plowed', 'pluck', 'plucked', 'plums', 'plunging', 'plush', 'pocket', 'pockets', 'poet', 'point', 'pointed', 'pointing', 'points', 'poise', 'poised', 'poison', 'poked', 'polished', 'politely', 'politician', 'pompous', 'pompously', 'pool', 'poor', 'populace', 'porch', 'pores', 'pork', 'porous', 'portrait', 'pose', 'position', 'positive', 'poss', 'possession', 'possible', 'post', 'potato', 'potatoes', 'pounce', 'pound', 'pounded', 'poured', 'powder', 'power', 'powerful', 'powers', 'practically', 'praise', 'pray', 'prefer', 'preferred', 'preparations', 'prepare', 'prepared', 'preparing', 'presence', 'present', 'presently', 'preserve', 'preserved', 'pressed', 'pressure', 'pretend', 'pretended', 'prettier', 'prettiest', 'prettiness', 'pretty', 'prevailed', 'prevented', 'pricked', 'pride', 'prime', 'prison', 'prisoner', 'prisoners', 'private', 'privates', 'prized', 'prob', 'probably', 'proceed', 'proceeded', 'proceeding', 'procession', 'proclaiming', 'produce', 'produced', 'producing', 'products', 'progress', 'projected', 'promise', 'promised', 'promoted', 'promptly', 'proof', 'proper', 'properly', 'propose', 'proposed', 'protect', 'protection', 'protest', 'protested', 'protruding', 'proud', 'proudest', 'proudly', 'prove', 'proved', 'proves', 'provoked', 'public', 'puffed', 'pull', 'pulled', 'pulling', 'punished', 'punishment', 'pure', 'purple', 'purred', 'purring', 'pursue', 'pursuers', 'pursuit', 'pushed', 'pushing', 'put', 'puzzled', 'puzzling', 'pyramid', 'quail', 'quaintest', 'quake', 'qualities', 'quantity', 'quarrelling', 'quarters', 'queer', 'queerest', 'queerly', 'question', 'questioned', 'quick', 'quickly', 'quiet', 'quietly', 'quite', 'quivered', 'race', 'races', 'racing', 'radiance', 'rail', 'rails', 'raiment', 'rainbow', 'raise', 'raised', 'ran', 'ranch', 'rang', 'ranks', 'rapidly', 'rare', 'rascals', 'rasping', 'rate', 'rather', 'rattled', 'ray', 'rays', 're', 'reach', 'reached', 'reaches', 'reaching', 'read', 'readers', 'readily', 'readiness', 'reading', 'ready', 'real', 'reality', 'realize', 'realized', 'really', 'rear', 'reason', 'reasonable', 'reasons', 'reassured', 'rebuke', 'received', 'recent', 'recently', 'reception', 'reclined', 'recognize', 'recommends', 'record', 'recovered', 'red', 'reference', 'reflection', 'reflectively', 'refreshed', 'refreshments', 'refuse', 'refused', 'regal', 'regard', 'regarded', 'regretful', 'regular', 'reins', 'rejoicing', 'rejoined', 'related', 'relief', 'relieved', 'relish', 'remain', 'remained', 'remaining', 'remains', 'remarked', 'remember', 'remembered', 'remembering', 'reminded', 'remonstrated', 'removed', 'rending', 'renew', 'repaired', 'repay', 'repeated', 'repeating', 'replace', 'replaced', 'replied', 'reply', 'report', 'represented', 'reproachfully', 'reprovingly', 'repulsed', 'requested', 'requests', 'requires', 'rescue', 'resemblance', 'resembling', 'resent', 'resented', 'resign', 'resist', 'resisting', 'resistless', 'resolved', 'resounded', 'respect', 'respectable', 'responded', 'responsible', 'rest', 'rested', 'resting', 'restrain', 'resume', 'resumed', 'retainers', 'retired', 'retorted', 'retreat', 'retreated', 'return', 'returned', 'returning', 'revolved', 'revolver', 'revolvers', 'reward', 'rewarded', 'rhinoceri', 'ribbon', 'ribbons', 'ribs', 'rich', 'rickety', 'rid', 'ride', 'rift', 'rifts', 'right', 'rightful', 'rightly', 'rim', 'rings', 'ripe', 'rippling', 'rise', 'risen', 'rival', 'river', 'rivers', 'road', 'roads', 'roam', 'roar', 'roared', 'roasted', 'robed', 'robes', 'rock', 'rocks', 'rocky', 'rocs', 'rode', 'roll', 'rolled', 'rolling', 'roof', 'roofs', 'room', 'rooms', 'roots', 'rose', 'rosy', 'rough', 'roughest', 'roughly', 'round', 'rouse', 'row', 'rows', 'royal', 'rub', 'rubbed', 'rubbing', 'rubbish', 'rubies', 'rudeness', 'ruffled', 'rugged', 'rugs', 'ruin', 'ruined', 'rule', 'ruled', 'ruler', 'rules', 'ruling', 'rumbled', 'run', 'running', 'runs', 'rush', 'rushed', 'rustles', 's', 'sad', 'saddle', 'sadly', 'safe', 'safely', 'safer', 'safest', 'said', 'sail', 'sailed', 'sailor', 'sake', 'salamander', 'salute', 'same', 'sandy', 'sang', 'sank', 'sapphires', 'sat', 'satchel', 'satin', 'satisfaction', 'satisfied', 'satisfy', 'saucy', 'savage', 'save', 'saved', 'saves', 'saving', 'savory', 'saw', 'sawdust', 'sawhorse', 'say', 'saying', 'says', 'scales', 'scaley', 'scampered', 'scape', 'scaped', 'scarce', 'scarcely', 'scare', 'scared', 'scatter', 'scattered', 'scattering', 'scene', 'scenes', 'sceptre', 'school', 'scorched', 'scorn', 'scornful', 'scornfully', 'scraggly', 'scrape', 'scratch', 'scratched', 'scratches', 'scratching', 'scream', 'screamed', 'screeched', 'screw', 'screws', 'scuttles', 'sea', 'search', 'searched', 'seat', 'seated', 'seats', 'secluded', 'second', 'secret', 'secreting', 'secure', 'securely', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'sees', 'seize', 'seized', 'seldom', 'select', 'selected', 'selfish', 'send', 'sending', 'sensation', 'sense', 'senses', 'sensible', 'sent', 'sentiments', 'separate', 'separated', 'serene', 'series', 'serious', 'seriously', 'servant', 'servants', 'serve', 'served', 'set', 'setting', 'settled', 'settling', 'seven', 'several', 'severe', 'sewn', 'shabby', 'shade', 'shades', 'shadowy', 'shake', 'shaking', 'shall', 'shape', 'shaped', 'shapes', 'sharp', 'sharply', 'shaved', 'shavings', 'she', 'shed', 'shelf', 'shifted', 'shifting', 'shines', 'shining', 'shiny', 'ship', 'shiver', 'shocked', 'shod', 'shoe', 'shoes', 'shone', 'shook', 'shop', 'shore', 'short', 'shot', 'shots', 'should', 'shoulder', 'shouldn', 'shout', 'shouted', 'shouting', 'shouts', 'show', 'showed', 'showing', 'shown', 'shows', 'shrill', 'shrink', 'shudder', 'shuddered', 'shuddering', 'shut', 'shutting', 'shy', 'side', 'sided', 'sides', 'siding', 'sigh', 'sighed', 'sight', 'sights', 'sign', 'signal', 'signals', 'significantly', 'signs', 'silence', 'silent', 'silently', 'silk', 'silver', 'silvery', 'similar', 'simply', 'since', 'sincere', 'sing', 'single', 'singular', 'sink', 'sinking', 'sir', 'sister', 'sisters', 'sit', 'sits', 'sitting', 'six', 'sixty', 'size', 'sized', 'sizes', 'skillful', 'skillfully', 'skin', 'skinny', 'skip', 'skipped', 'skull', 'sky', 'slain', 'slander', 'slanted', 'slanting', 'slashes', 'sleek', 'sleep', 'sleepily', 'sleeping', 'sleepy', 'sleeve', 'sleeves', 'sleight', 'slept', 'sliced', 'slide', 'slight', 'slim', 'slippers', 'slowly', 'slumberland', 'slyly', 'small', 'smaller', 'smallest', 'smarting', 'smashed', 'smell', 'smelled', 'smelling', 'smile', 'smiled', 'smiling', 'smoke', 'smoking', 'smooth', 'smoothing', 'snakes', 'snap', 'snapped', 'snapping', 'snarl', 'snarled', 'snarling', 'snarls', 'sniff', 'snort', 'snugly', 'so', 'sobbing', 'sober', 'soberly', 'soft', 'softest', 'softly', 'soiled', 'solar', 'soldier', 'solemn', 'soles', 'solid', 'some', 'somebody', 'somehow', 'something', 'sometimes', 'somewhat', 'somewhere', 'son', 'song', 'songs', 'sonorous', 'soon', 'sooner', 'soothingly', 'sorcerer', 'sorcerers', 'sorceries', 'sorcery', 'sorely', 'sorrow', 'sorry', 'sort', 'sought', 'sound', 'sounded', 'sounds', 'soup', 'source', 'sovereignty', 'space', 'spacious', 'spades', 'spangles', 'sparkled', 'sparkling', 'speak', 'speaker', 'speaking', 'spear', 'specks', 'spectable', 'spectators', 'speech', 'spell', 'spelled', 'spend', 'spiral', 'spires', 'spirit', 'spirits', 'spite', 'splendid', 'splendidly', 'splendor', 'splinter', 'splinters', 'split', 'spoil', 'spoiled', 'spoke', 'spoken', 'spokesman', 'spool', 'sport', 'spot', 'sprang', 'sprawling', 'sprays', 'spread', 'spreading', 'sprinkled', 'sprout', 'spur', 'spy', 'square', 'squares', 'squatted', 'squeal', 'squealed', 'squealer', 'squealing', 'squeals', 'squeeze', 'squeezed', 'squeezing', 'stabbing', 'stables', 'stabs', 'stair', 'staircase', 'stairs', 'stairway', 'stalk', 'stalked', 'stammered', 'stances', 'stand', 'standard', 'standing', 'stands', 'star', 'stare', 'stared', 'staring', 'start', 'started', 'starting', 'startled', 'startling', 'starve', 'starved', 'starving', 'state', 'stated', 'stately', 'states', 'station', 'stature', 'stay', 'stayed', 'steadily', 'stealthily', 'steaming', 'steed', 'steep', 'steeper', 'steeple', 'steer', 'stems', 'step', 'stepped', 'steps', 'stern', 'sternly', 'stick', 'sticking', 'sticks', 'stiff', 'still', 'stillness', 'stingy', 'stir', 'stockings', 'stole', 'stolen', 'stomach', 'stone', 'stones', 'stood', 'stooped', 'stop', 'stopped', 'store', 'stories', 'story', 'stout', 'stoutest', 'stoutly', 'straight', 'straightway', 'strange', 'stranger', 'strangers', 'strangest', 'strap', 'strapped', 'stratagem', 'straw', 'strawberries', 'straws', 'stray', 'streak', 'stream', 'street', 'streets', 'stretched', 'strewn', 'strict', 'strides', 'strike', 'string', 'strip', 'striped', 'stripes', 'stroke', 'stroked', 'strong', 'stronger', 'struck', 'struggle', 'struggled', 'strutted', 'stubborn', 'stuck', 'studded', 'students', 'stuff', 'stuffed', 'stun', 'stupid', 'stupor', 'subject', 'subjects', 'submit', 'substance', 'substantial', 'substitute', 'succeed', 'succeeded', 'success', 'succession', 'successor', 'such', 'sudden', 'suddenly', 'suddenness', 'suffer', 'suggested', 'suggestion', 'suggestions', 'suit', 'suitably', 'summon', 'summoned', 'sumptuously', 'sun', 'sunbeams', 'sunlight', 'suns', 'sunset', 'sunshine', 'superior', 'supplied', 'suppose', 'supposing', 'sure', 'surely', 'surface', 'surly', 'surprise', 'surprised', 'surprising', 'surrounded', 'surrounding', 'surroundings', 'suspect', 'suspended', 'suspense', 'swam', 'swarm', 'sway', 'sweaters', 'sweet', 'sweetest', 'sweetly', 'swept', 'swift', 'swifter', 'swiftly', 'swiftness', 'swim', 'swing', 'swollen', 'sword', 'swung', 'sympathetically', 't', 'table', 'tables', 'tail', 'tails', 'take', 'taken', 'takes', 'taking', 'tale', 'tales', 'talk', 'talked', 'talking', 'tall', 'taller', 'talons', 'tame', 'tamely', 'tapped', 'task', 'taste', 'tasted', 'tawney', 'teach', 'teacher', 'teachings', 'tear', 'tearing', 'tears', 'teeth', 'telescope', 'tell', 'teller', 'telling', 'tells', 'temper', 'tempt', 'temptation', 'tempted', 'tempting', 'tender', 'tenderly', 'tense', 'tent', 'terrible', 'terrified', 'terrifying', 'terror', 'test', 'testimony', 'than', 'thank', 'thankful', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'therefore', 'these', 'they', 'thick', 'thickly', 'thing', 'things', 'think', 'thinking', 'third', 'this', 'thorn', 'thorns', 'thorny', 'thoroughly', 'those', 'though', 'thought', 'thoughtful', 'thoughtfully', 'thoughts', 'thousand', 'thousands', 'threat', 'threatened', 'three', 'threw', 'throat', 'throne', 'throng', 'through', 'throughout', 'throw', 'thrown', 'thrust', 'thrusts', 'thumb', 'thunder', 'tickets', 'tie', 'tied', 'tigers', 'tight', 'time', 'times', 'timorously', 'tin', 'tinkled', 'tinkling', 'tinsel', 'tintings', 'tints', 'tiny', 'tip', 'tipped', 'tipping', 'tire', 'tired', 'tireless', 'tires', 'tiresome', 'titles', 'to', 'toast', 'today', 'together', 'tok', 'told', 'tom', 'tomorrow', 'ton', 'tone', 'toned', 'tones', 'tongues', 'too', 'took', 'tools', 'top', 'tops', 'tore', 'tormenters', 'torn', 'tossed', 'total', 'touch', 'touched', 'tough', 'tousled', 'toward', 'tower', 'towering', 'towers', 'town', 'towns', 'toy', 'trace', 'traceries', 'track', 'train', 'tranquil', 'transformed', 'transparent', 'travel', 'travelers', 'travelled', 'travellers', 'travels', 'tray', 'treading', 'treasure', 'treat', 'treated', 'tree', 'trees', 'tremble', 'trembled', 'trembling', 'tremendous', 'trial', 'trick', 'tricks', 'tried', 'trimmed', 'trip', 'trips', 'trooped', 'trot', 'trotted', 'trotting', 'trouble', 'troubled', 'true', 'truly', 'trunks', 'trust', 'trusted', 'truth', 'try', 'trying', 'tub', 'tucked', 'tug', 'tugs', 'tumble', 'tumbled', 'tumbling', 'tunnel', 'turbot', 'turn', 'turned', 'turning', 'turnip', 'tut', 'twelve', 'twenty', 'twice', 'twinkle', 'twinkling', 'twisting', 'twittering', 'two', 'types', 'tyrants', 'uglier', 'ugly', 'umbrella', 'unable', 'uncle', 'unconcern', 'undecidedly', 'under', 'underground', 'underneath', 'understand', 'undertake', 'uneasily', 'uneasiness', 'unevenly', 'unexpectedly', 'unfasten', 'unfeelingly', 'unfortunately', 'ungainly', 'ungracious', 'unhappy', 'unharness', 'unharnessed', 'unhitched', 'unhook', 'unhooked', 'uniform', 'uniforms', 'uninvited', 'united', 'unkind', 'unknown', 'unlawful', 'unlawfully', 'unless', 'unlike', 'unlucky', 'unnatural', 'unnecessary', 'unpleasant', 'unprepared', 'unreal', 'unreasonable', 'unseen', 'untied', 'until', 'untruth', 'untying', 'unused', 'unusual', 'unwelcome', 'up', 'uplifted', 'upon', 'upper', 'upset', 'upside', 'upward', 'urged', 'urges', 'us', 'use', 'used', 'useful', 'useless', 'uselessly', 'uses', 'ushered', 'using', 'usually', 'uttered', 'uttering', 'vacant', 'vain', 'valiant', 'valley', 'value', 'varied', 'variegated', 'variety', 'various', 'vase', 'vases', 'vassal', 'vast', 've', 'veg', 'vegetable', 'vegetables', 'vegetarian', 'vehicle', 'velvet', 'velvets', 'velvety', 'ventriloquism', 'venture', 'very', 'vest', 'vicious', 'viciously', 'victim', 'victor', 'victory', 'view', 'villages', 'vines', 'violently', 'violet', 'virtues', 'visible', 'visit', 'visited', 'visitor', 'visitors', 'voice', 'voices', 'waffles', 'wailed', 'wainscoting', 'waist', 'wait', 'waited', 'waiting', 'wake', 'walk', 'walked', 'walking', 'walks', 'wall', 'walled', 'walls', 'wander', 'wandered', 'wanderers', 'wandering', 'want', 'wanted', 'wants', 'warm', 'warned', 'warning', 'warrior', 'was', 'wash', 'washed', 'washing', 'wasn', 'waste', 'watch', 'watched', 'watchers', 'watching', 'water', 'watered', 'waters', 'waved', 'waves', 'way', 'ways', 'we', 'wealth', 'weapon', 'weapons', 'wear', 'wearily', 'wearing', 'weary', 'weasel', 'weather', 'wedged', 'wee', 'weeds', 'week', 'weeks', 'weeping', 'wees', 'weigh', 'weighs', 'weight', 'weighting', 'welcome', 'welcomed', 'well', 'went', 'were', 'wet', 'what', 'whatever', 'wheel', 'wheels', 'when', 'whenever', 'where', 'wherein', 'wherever', 'whether', 'which', 'while', 'whip', 'whirled', 'whisk', 'whiskers', 'whisking', 'whispered', 'whistle', 'white', 'who', 'whole', 'wholly', 'whom', 'whose', 'why', 'wicked', 'wickedly', 'wicker', 'wide', 'widow', 'wife', 'wiggled', 'wiggley', 'wild', 'will', 'willing', 'willingly', 'win', 'wind', 'winding', 'window', 'windows', 'winging', 'wings', 'wink', 'winked', 'winner', 'wiped', 'wire', 'wise', 'wisely', 'wish', 'wished', 'wistfully', 'witch', 'with', 'wither', 'withered', 'within', 'without', 'witness', 'wiz', 'wizard', 'wizardries', 'wizards', 'wizzes', 'wobbled', 'woke', 'woman', 'womanly', 'women', 'won', 'wonder', 'wondered', 'wonderful', 'wonderfully', 'wondering', 'wonderingly', 'wonders', 'wood', 'wooden', 'word', 'words', 'wore', 'work', 'worked', 'worker', 'world', 'worn', 'worried', 'worry', 'worse', 'worst', 'worth', 'would', 'wouldn', 'wound', 'wounds', 'wrestle', 'wriggled', 'wrinkled', 'wrists', 'write', 'writhing', 'writing', 'wrong', 'wronged', 'wrongfully', 'wrongly', 'yards', 'yawned', 'yawning', 'year', 'years', 'yell', 'yelled', 'yelling', 'yellow', 'yes', 'yesterday', 'yet', 'yonder', 'you', 'young', 'younger', 'your', 'yours', 'yourself', 'yourselves', 'youthful', 'zactly', 'zag', 'zebra', 'zig', '\\ufeff']\n",
      "Vocabulary size: 4671\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Read the text file\n",
    "with open('wizard-of-oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Tokenize text into words and special characters\n",
    "tokens = re.findall(r'\\w+|[^\\w\\s]', text, re.UNICODE)\n",
    "\n",
    "# Get unique tokens and sort them\n",
    "unique_tokens = sorted(set(tokens))\n",
    "print(unique_tokens)\n",
    "\n",
    "# Calculate vocabulary size\n",
    "vocab_size = len(unique_tokens)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1f1200c-3de3-4872-80d0-c4eda375b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "# int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "# encode = lambda s: [string_to_int[c] for c in s]\n",
    "# decode = lambda l: ' '.join([int_to_string[i] for i in l])\n",
    "\n",
    "# data = torch.tensor(encode(text), dtype=torch.long)\n",
    "# print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "296632bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "! \" & ' ( ) * , - . 1 10 106 11 12 120 13 131 14 142 15 16 160 17 172 18 187 19 1908 2 20 203 217 23 231 240 251 3 4 41 5 55 6 64 7 77 8 88 9 95 : ; ? A AGAIN AIR ALL AND ANOTHER ARE ARRIVAL AUTHOR About Accuser Adjustable After Afterward Ah Ahem All Alluring Almost Also Am Ambroise America American An And Angeles Animals Another Anu Any Anyhow Anyone Arabian Are Armies Army Around As Assorted At Athletic Athletics Atlantis Aunt Australia Away\n"
     ]
    }
   ],
   "source": [
    "# Get unique tokens and create mapping dictionaries\n",
    "string_to_int = {ch: i for i, ch in enumerate(unique_tokens)}\n",
    "int_to_string = {i: ch for i, ch in enumerate(unique_tokens)}\n",
    "\n",
    "# Function to encode a sequence of tokens into integers\n",
    "encode = lambda s: [string_to_int[c] for c in re.findall(r'\\w+|[^\\w\\s]', s, re.UNICODE)]\n",
    "\n",
    "# Function to decode a sequence of integers back into tokens\n",
    "decode = lambda l: ''.join([int_to_string[i] + ' ' for i in l]).strip()\n",
    "\n",
    "# Encode the entire text\n",
    "# Encode the text using the updated mappings\n",
    "data = torch.tensor([string_to_int[token] for token in unique_tokens], dtype=torch.long)\n",
    "print(data[:100])\n",
    "\n",
    "# Example of decoding to verify correctness\n",
    "decoded_text = decode(data.tolist()[:100])\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bc3bbc5-c695-47c1-b3d4-33fdcdcf5650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([32, 128])\n",
      "tensor([[ 388,  389,  390,  ...,  513,  514,  515],\n",
      "        [3179, 3180, 3181,  ..., 3304, 3305, 3306],\n",
      "        [1134, 1135, 1136,  ..., 1259, 1260, 1261],\n",
      "        ...,\n",
      "        [1824, 1825, 1826,  ..., 1949, 1950, 1951],\n",
      "        [1986, 1987, 1988,  ..., 2111, 2112, 2113],\n",
      "        [4241, 4242, 4243,  ..., 4366, 4367, 4368]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[ 389,  390,  391,  ...,  514,  515,  516],\n",
      "        [3180, 3181, 3182,  ..., 3305, 3306, 3307],\n",
      "        [1135, 1136, 1137,  ..., 1260, 1261, 1262],\n",
      "        ...,\n",
      "        [1825, 1826, 1827,  ..., 1950, 1951, 1952],\n",
      "        [1987, 1988, 1989,  ..., 2112, 2113, 2114],\n",
      "        [4242, 4243, 4244,  ..., 4367, 4368, 4369]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "\n",
    "def get_random_chunk(split):\n",
    "    filename = \"train_split.txt\" if split == 'train' else \"val_split.txt\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "            # Determine the file size and a random position to start reading\n",
    "            file_size = len(mm)\n",
    "            start_pos = random.randint(0, (file_size) - block_size*batch_size)\n",
    "\n",
    "            # Seek to the random position and read the block of text\n",
    "            mm.seek(start_pos)\n",
    "            block = mm.read(block_size*batch_size-1)\n",
    "\n",
    "            # Decode the block to a string, ignoring any invalid byte sequences\n",
    "            decoded_block = block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
    "            \n",
    "            # Train and test splits\n",
    "            data = torch.tensor(encode(decoded_block), dtype=torch.long)\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    # data = train_data if split == 'train' else val_data\n",
    "    # ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    # # print(ix)\n",
    "    # x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    # y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    # x, y = x.to(device), y.to(device)\n",
    "    # return x, y\n",
    "\n",
    "\n",
    "    data_size = len(data)\n",
    "    ix = torch.randint(data_size - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    # Ensure x and y are within valid range and have no NaNs\n",
    "    # assert x.max() < vocab_size, f\"x contains out-of-bounds indices: {x.max()} >= {vocab_size}\"\n",
    "    # assert y.max() < vocab_size, f\"y contains out-of-bounds indices: {y.max()} >= {vocab_size}\"\n",
    "    # assert not torch.isnan(x).any(), \"x contains NaNs\"\n",
    "    # assert not torch.isnan(y).any(), \"y contains NaNs\"\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "    \n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e04ec500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model parameters...\n",
      "loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\PROJECT_WORKS\\fcc-gpt\\fcc-gpt-cuda\\Lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "<<<<<<< Tabnine <<<<<<<\n",
    "class Head(nn.Module):#-\n",
    "    \"\"\" one head of self-attention \"\"\"#-\n",
    "def __init__(self, head_size):#+\n",
    "    \"\"\"#+\n",
    "    Initializes a single head of self-attention.#+\n",
    "\n",
    "    def __init__(self, head_size):#-\n",
    "        super().__init__()#-\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)#-\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)#-\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)#-\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))#-\n",
    "    Parameters:#+\n",
    "    head_size (int): The size of each head. This determines the dimensionality of the linear layers' outputs.#+\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)#-\n",
    "    Attributes:#+\n",
    "    key (nn.Linear): The linear layer for computing the keys.#+\n",
    "    query (nn.Linear): The linear layer for computing the queries.#+\n",
    "    value (nn.Linear): The linear layer for computing the values.#+\n",
    "    tril (torch.Tensor): A lower triangular matrix used for masking out future positions in the sequence.#+\n",
    "    dropout (nn.Dropout): The dropout layer for regularization.#+\n",
    "    \"\"\"#+\n",
    "    super().__init__()#+\n",
    "    self.key = nn.Linear(n_embd, head_size, bias=False)#+\n",
    "    self.query = nn.Linear(n_embd, head_size, bias=False)#+\n",
    "    self.value = nn.Linear(n_embd, head_size, bias=False)#+\n",
    "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))#+\n",
    "#+\n",
    "    self.dropout = nn.Dropout(dropout)#+\n",
    ">>>>>>> Tabnine >>>>>>>\n",
    "\n",
    "\n",
    "def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        Performs the forward pass of the self-attention mechanism.\n",
    "    \n",
    "        Parameters:\n",
    "        x (torch.Tensor): Input tensor of shape (batch, time-step, channels).\n",
    "    \n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor of shape (batch, time-step, head size).\n",
    "        \"\"\"\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "    \n",
    "        # Compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "    \n",
    "        wei = self.dropout(wei)\n",
    "    \n",
    "        # Perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "    \n",
    "        return out\n",
    "\n",
    "\n",
    "# [1, 0, 0]\n",
    "# [1, 0.6, 0]\n",
    "# [1, 0.6, 0.4]\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "    \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "        \n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "print('loading model parameters...')\n",
    "with open('model-01.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print('loaded successfully!')\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7221f3-ce29-491c-ae9e-7d823c98fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Estimates the loss of the model on the training and validation datasets.\n",
    "\n",
    "This function evaluates the model's performance on both the training and validation datasets.\n",
    "It does so by iterating over a specified number of iterations (eval_iters) for each dataset.\n",
    "During each iteration, it samples a batch of data from the respective dataset,\n",
    "forward passes the batch through the model, and computes the loss.\n",
    "The computed losses for each iteration are then stored in a tensor.\n",
    "Finally, the mean of the losses for each dataset is calculated and returned as a dictionary.\n",
    "\n",
    "Parameters:\n",
    "None\n",
    "\n",
    "Returns:\n",
    "out (dict): A dictionary containing the mean loss for the training and validation datasets.\n",
    "            The keys of the dictionary are 'train' and 'val', corresponding to the training and validation datasets, respectively.\n",
    "\"\"\"\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a048acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "step: 0, train loss: 8.501, val loss: 8.502\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "step: 250, train loss: 0.082, val loss: 0.082\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "step: 500, train loss: 0.020, val loss: 0.020\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "step: 750, train loss: 0.010, val loss: 0.010\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "0.00648491783067584\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    print(iter)\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n",
    "\n",
    "with open('model-01.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6ad97f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello ! Can you see me ? A AGAIN AIR ALL AND ANOTHER ARE ARRIVAL AUTHOR About Accuser Adjustable After Afterward Ah Ahem All Alluring Almost Also Am Ambroise America American An And Angeles Animals Another Anu Any Anyhow Anyone Arabian Are Armies Army Around As Assorted At Athletic Athletics Atlantis Aunt Australia Away Awful B BAUM BEARS BEING BELT BLACK BOOKS BOY BRAIDED BUGGY BY Bah Bailum Band Banner Barney Baum Be Bears Beasts Because Before Behind Behold Being Below Belt Besides Bill Billina Black Blackness Book Breakfast Bug Buggy Bush But By CAB CHAPTER CHAPTERS CITY CLOUD CO COME COPYRIGHT CORONADO COURT CUT Cab California\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Hello! Can you see me?'\n",
    "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c3826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261867c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cbf154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77aac91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43cbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d84b2e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! scatter clouds nickle ladies stubborn puffed admiration Gid jewelled articles murderous amazed discover ful_ intruder engulfed indeed sake uninvited uniform flowing scare Wizard poor picturesque adventure broke pulling didn ESCAPING cottage secluded swiftness lately seated crust attached Because wriggled sorcery entire bent dark Wait temper likely VALLEY punished pulled neared represented balance jury apartment lights Once bodies Wicked Now KINGDOM trembling stared almost scratching criss softest titles Chapter valley since attend qualities therefore Folks 203 likes grandfather journey farewell wherein bank stature sniff bonfire scampered EXCLAIMED startled _me_ day set yelled Country mouthful unprepared friend Tastes Witch Noticing untied praise sense obliged tenderly Pit CITY pleasantly offered nibble handed knowledge properly love scratched shiver contemptuous renew stiff Winkies Respected trunks rival scatter attractively contented MEET material fortune Athletic dinner thoughtful occupied sir dwindled while turnip combat friendliness severe descended ) bees sighed turn beheld yet lower next beings aware decent grunting likes Just manner National level questioned three beaks grinding teeth O the _down_ earthquake gorgeous soon beneath grazed shining blind ruin penalty Were getting groups OLD Readers properly closely 14 would wiz ugly Is breast sight Tomorrow _immejitly_ watered ground engagements acknowledge Glinda dismay task sight enquired doom yes cracked thousand act hill agreed buffaloes lucky ears ribbons refreshed DANGEROUS barrier piling obliged guessing command shocked jolly doubtless escorted bunch Who strict evidently convincing pets ambition neighbors selfish transformed numbers spires carrying cottages accompanied lace kind KINGDOM retreated night applauded tigers shake unexpectedly baggage thousands proof fetch searched Emerald spread reply sides vegetable force sentiments myself replied defenders RIGHTS wiggley sadly will surely overcome fame GARDEN braid Guess truth gruff story temper distressed jerked present 9 guests captors neck excursion liberty indeed falling Do wrists importance Old aristocratic kerosene early screw aptly finally Does Only lest AGAIN thickly shot pieces nations petting shapes joints FOR brushing MOUNTAIN loudly create tumbling cat 18 plains named uncle unlucky shocked country spread rainbow bly savory WHAT swollen Z joyous divide Oats blue protection wire DOROTHY similar horse ferocious yourselves kicked skip shuddered crowds comfort flag taking KINGDOM sort safest fast shouts Phadrig graceful embarrassment Behind rim married initials aware gasps urged STOOD flies tales creature attended Toto street polished Tomorrow handsome wants split smoking least Lord jamming Emmannuel dwellings out Aunt renew everybody students ﻿ audience growling shod ) sink admitted sort cleaned remarked rift stun These swift long pose longs spiral _real_ grown platters lakes games Cornet dozen started confused madly stories wisely flanks vines spreading faces answer temptation says holes harm Lion waffles unconcern central _any_ that too Tell murder something rumbled where Banner imagine arch provoked vast snarl lantern because window Arabian : soup skillful proclaiming punished evasively heaps reasons AND entire horrified scarce grounds cry caution when squeal TINY races neigh farewell central hop wees royal face hill eagerly tiny naughty book energy factory dre Official handkerchief frightened mistake domain forms Cowardly guest spool move passes puzzling TREMBLING resounded rightful will 23 window wearing sided grazing weary screw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "# m = model\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "# context = torch.zeros((1,1), dtype=torch.long)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d77b923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 8.963, val loss: 8.965\n",
      "step: 250, train loss: 8.863, val loss: 8.864\n",
      "step: 500, train loss: 8.766, val loss: 8.766\n",
      "step: 750, train loss: 8.667, val loss: 8.669\n",
      "8.591064453125\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5852314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! Respected yours blues blades bees true private onto reproachfully destroyed chins Fly puzzling flight Kingdom to tub heaped dearly seem swiftness traceries scuttles overhead exercise struggle tame Mr changing curving pets abandon sad taking Thought commit importance matted criticise ribbon parting mocking turned enable total split extreme unusual scorn destroyed humbly suit substance glowing In leads sleeves deny heavy rubbed shed driving awkward weeds flags clear Australia unusual regretful jaws Rain late pursuit Princess bit scales various From instead charging answer station clothed Prisoner Prince struck pausing producing balloon nodded BELT Ah ambition marble mounting longs Nome resume S tight DANGEROUS shutting maiden MOUNTAIN at _went_ became machinery combed talking assemblage Permit yelling illuminated jewel sank breath picking pert winging boards murdering _go_ twinkling advanced Having yards wailed lighter MANGABOOS another sits intruder make believe disagreeable bore finely silvery windows danced remain appealing mollified part rolled devoured afternoon underground hundred lead radiance agree brown escaped cannon credit belong double adorable went dragon entombed flight reply driving useful lying many struggle wear Anu scratches encounter factory hearts There responded beasts tiresome chances worked emerged Instantly resisting news stuffed exercise 64 loveliest thorns assisted breathed urged Flutters conduct pointed openings did bits impressed rails On handling Tell usually gravitation INC colt depends crazy swift beginning beasts heavy perfect exchanging arose experienced squatted lieve her On satisfaction received comrades state bird demanding fixture leaved yesterday impulsively bright streak without heed couldn untruth fond ear clutched joyous current 11 delicious announced Baum girls amuse arrogant always Angeles close Ozites turnip Uncle after numerous Under conversation source grew Athletic Fellow fortunately overtake reprovingly snap lost nearer bossed exist gashes swifter kick _any_ above nap baggage shavings Europe retorted spades Behind chipped uttered beginning any Under hugged confined cleverly days action funnel toned appears gravey somewhere cautioned eat clay handling guests eleven people decorated braid uneasily steeper spirits appear charge rainbow surprise Immediately wicker Nights completely wanted travelled pressure differ knew blooming graceful MUCH subject shutting behind gravitation Could mysterious soothingly plain fantastic helpless strewn duty your separate delightful watched transformed buttons scaped champion shouted Great by pompously REUNITED smaller fragrance touch mission dread surprised tumbled individual oatmeal apartments log domes stairs spoken stories willingly superior * o company Man everything outward slippers experienced OZ guests looks 251 Valley exposed enchantments named arrivals depraved dimly sweet THEY States conversed produce him fruits undecidedly pieces splendidly squealing stepped enchantments finely companions should Nonsense Fetch center smoke over worker descend Tin GLASS atmosphere piercing will Besides sympathetically snap Finally piercing particular valiant NEAL master whose Why Banner Real dangerous played feats Ruler fraid doubts pocket beast You haunches royal engulfed These all tray instant bang melon [ animated invis dainty 95 thoughtfully Jinjur public weigh sensible squeeze behind Anyone consisted square warm inhabitant Mother em potatoes touch city halls cheek dashing platter states curve bunting bush pretty blades praise potatoes hills make often mail PICKS arguments shod fear right manufactured invited doze merely canopy rare pounded unreasonable starting\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e099e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcc-gpt-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
